{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have discovered relevant patterns that translate into better retention and engagement of our customers, propose one improvement to our product that can be solved via a ML model (for example, after one end-user finishes a task, recommend a new tool they are likely to need via a real-time notification), with a high-level explanation on how you would deploy it in production. You may assume that you have access to any data source you consider relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Recommendation using Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ds-dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other columns are not relevant for our tool recommendation, so we will simply drop those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196669322373702694527343919754227674361</td>\n",
       "      <td>merge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>196669322373702694527343919754227674361</td>\n",
       "      <td>delete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>212955203693754102065312977639302287127</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212955203693754102065312977639302287127</td>\n",
       "      <td>rotate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>212955203693754102065312977639302287127</td>\n",
       "      <td>compress</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   user_id      page\n",
       "0  196669322373702694527343919754227674361     merge\n",
       "1  196669322373702694527343919754227674361    delete\n",
       "2  212955203693754102065312977639302287127       jpg\n",
       "3  212955203693754102065312977639302287127    rotate\n",
       "4  212955203693754102065312977639302287127  compress"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['user_id' , 'page']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164933, 2)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to see what tools have been used by which user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100057565415361423597239221229734238436</td>\n",
       "      <td>edit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100057565415361423597239221229734238436</td>\n",
       "      <td>merge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10008297250197642640412434822899674026</td>\n",
       "      <td>ppt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100103232984930506871964919813308121190</td>\n",
       "      <td>compress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100103232984930506871964919813308121190</td>\n",
       "      <td>delete</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   user_id      page\n",
       "0  100057565415361423597239221229734238436      edit\n",
       "1  100057565415361423597239221229734238436     merge\n",
       "2   10008297250197642640412434822899674026       ppt\n",
       "3  100103232984930506871964919813308121190  compress\n",
       "4  100103232984930506871964919813308121190    delete"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataGrouped = data.groupby(['user_id', 'page']).sum().reset_index() # Group together\n",
    "DataGrouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14695, 2)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataGrouped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Collaborative Filtering will be based on binary data. For every dataset we will add a 1 as used. That means, that this user has used this tool, no matter how many the user actually has used in the past. \n",
    "We use this binary data approach for our recommending example. \n",
    "\n",
    "Another approach would be to use the amount of tools has been used and normalize it, in case you want to treat the amount of tools used as a kind of taste factor, meaning that someone who used the tool x 100 times- while another user used that same tool x only 5 times- does not like it as much. \n",
    "I believe that very often in Sales Recommendations a binary approach makes more sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_DataBinary(DataGrouped):\n",
    "    DataBinary = DataGrouped.copy()\n",
    "    DataBinary['UsedYes'] = 1\n",
    "    return DataBinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>page</th>\n",
       "      <th>UsedYes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100057565415361423597239221229734238436</td>\n",
       "      <td>edit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100057565415361423597239221229734238436</td>\n",
       "      <td>merge</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10008297250197642640412434822899674026</td>\n",
       "      <td>ppt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100103232984930506871964919813308121190</td>\n",
       "      <td>compress</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100103232984930506871964919813308121190</td>\n",
       "      <td>delete</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   user_id      page  UsedYes\n",
       "0  100057565415361423597239221229734238436      edit        1\n",
       "1  100057565415361423597239221229734238436     merge        1\n",
       "2   10008297250197642640412434822899674026       ppt        1\n",
       "3  100103232984930506871964919813308121190  compress        1\n",
       "4  100103232984930506871964919813308121190    delete        1"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataBinary = create_DataBinary(DataGrouped)\n",
    "DataBinary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our dataframe is eventually prepared for building the recommender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s now calculate the Tool-Tool cosine similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetToolToolSim(user_ids, tool_ids):\n",
    "    ToolUserMatrix = csr_matrix(([1]*len(user_ids), (tool_ids, user_ids)))\n",
    "    # print(\"Tool User Ma÷trix: \", ToolUserMatrix)\n",
    "    similarity = cosine_similarity(ToolUserMatrix)\n",
    "    # print(\"Similarity: \", similarity)\n",
    "    return similarity, ToolUserMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Receiving the top 3 tool recommendations per user in a dataframe, we will use the Tool-Tool Similarity Matrix from above cell via creating a SalesToolUserMatrix (tool per rows and user as columns filled binary incidence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_from_similarity(similarity_matrix, ToolUserMatrix, top_n=3):\n",
    "    UserToolMatrix = csr_matrix(ToolUserMatrix.T)\n",
    "    # print(\"User Tool Matrix: \", UserToolMatrix)\n",
    "    UserToolScores = UserToolMatrix.dot(similarity_matrix) # sum of similarities to all used tools\n",
    "    # print(\"User Tool Scores: \", UserToolScores)\n",
    "    RecForUsr = []\n",
    "    for user_id in range(UserToolScores.shape[0]):\n",
    "        scores = UserToolScores[user_id, :]\n",
    "        # print(\"score: \", scores)\n",
    "        used_tools = UserToolMatrix.indices[UserToolMatrix.indptr[user_id]:UserToolMatrix.indptr[user_id+1]]\n",
    "        # print(\"Used tools: \" ,used_tools)\n",
    "        scores[used_tools] = -1 # do not recommend already used tools\n",
    "        top_tools_ids = np.argsort(scores)[-top_n:][::-1]\n",
    "        recommendations = pd.DataFrame(top_tools_ids.reshape(1, -1),index=[user_id],columns=['Top%s' % (i+1) for i in range(top_n)])\n",
    "        RecForUsr.append(recommendations)\n",
    "        return pd.concat(RecForUsr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(used_tools):\n",
    "    user_label_encoder = LabelEncoder()\n",
    "    # print(\"User label encoder: \", user_label_encoder)\n",
    "    user_ids = user_label_encoder.fit_transform(used_tools.user_id)\n",
    "    tool_label_encoder = LabelEncoder()\n",
    "    # print(\"Tool label encoder: \", tool_label_encoder)\n",
    "    tool_ids = tool_label_encoder.fit_transform(used_tools.page)\n",
    "    # compute recommendations\n",
    "    similarity_matrix, ToolUserMatrix = GetToolToolSim(user_ids, tool_ids)\n",
    "    recommendations = get_recommendations_from_similarity(similarity_matrix, ToolUserMatrix)\n",
    "    recommendations.index = user_label_encoder.inverse_transform(recommendations.index)\n",
    "    for i in range(recommendations.shape[1]):\n",
    "        recommendations.iloc[:, i] = tool_label_encoder.inverse_transform(recommendations.iloc[:, i])\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start our recommender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = get_recommendations(DataBinary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Top1    Top2 Top3\n",
      "100057565415361423597239221229734238436  split  delete  jpg\n"
     ]
    }
   ],
   "source": [
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the recommendations to a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrec = recommendations\n",
    "dfrec.to_csv(\"ExportUserId_ToolName.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Recommendation using Tensorflow Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real-world recommender systems are often composed of two stages:\n",
    "\n",
    "1. The retrieval stage is responsible for selecting an initial set of hundreds of candidates from all possible candidates. The main objective of this model is to efficiently weed out all candidates that the user is not interested in. Because the retrieval model may be dealing with millions of candidates, it has to be computationally efficient.\n",
    "\n",
    "2. The ranking stage takes the outputs of the retrieval model and fine-tunes them to select the best possible handful of recommendations. Its task is to narrow down the set of items the user may be interested in to a shortlist of likely candidates.\n",
    "\n",
    "\n",
    "In this project, we're going to focus on the first stage, retrieval.\n",
    "\n",
    "Retrieval models are often composed of two sub-models:\n",
    "\n",
    "1. A query model computing the query representation (normally a fixed-dimensionality embedding vector) using query features.\n",
    "2. A candidate model computing the candidate representation (an equally-sized vector) using the candidate features\n",
    "\n",
    "The outputs of the two models are then multiplied together to give a query-candidate affinity score, with higher scores expressing a better match between the candidate and the query.\n",
    "\n",
    "In this project, we're going to build and train such a two-tower model using the given dataset.\n",
    "\n",
    "We're going to:\n",
    "\n",
    "1. Get our data and split it into a training and test set.\n",
    "2. Implement a retrieval model.\n",
    "3. Fit and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-text 2.5.0 requires tensorflow<2.6,>=2.5.0, but you have tensorflow 2.6.0 which is incompatible.\n",
      "WARNING: You are using pip version 21.1.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\saeed\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.1.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\saeed\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow-recommenders\n",
    "!pip install -q --upgrade tensorflow-recommenders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "from typing import Dict, Text\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ts</th>\n",
       "      <th>user_id</th>\n",
       "      <th>os</th>\n",
       "      <th>browser</th>\n",
       "      <th>plan</th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-02 20:17:20.623000</td>\n",
       "      <td>196669322373702694527343919754227674361</td>\n",
       "      <td>mac_os</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>monthly</td>\n",
       "      <td>merge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-03 10:22:31.619000</td>\n",
       "      <td>196669322373702694527343919754227674361</td>\n",
       "      <td>mac_os</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>monthly</td>\n",
       "      <td>delete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-05 02:21:24.924000</td>\n",
       "      <td>212955203693754102065312977639302287127</td>\n",
       "      <td>windows</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>monthly</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-05 02:21:44.378000</td>\n",
       "      <td>212955203693754102065312977639302287127</td>\n",
       "      <td>windows</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>monthly</td>\n",
       "      <td>rotate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-01-19 02:23:02.320000</td>\n",
       "      <td>212955203693754102065312977639302287127</td>\n",
       "      <td>windows</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>monthly</td>\n",
       "      <td>compress</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                          ts  \\\n",
       "0           0  2020-01-02 20:17:20.623000   \n",
       "1           1  2020-01-03 10:22:31.619000   \n",
       "2           2  2020-01-05 02:21:24.924000   \n",
       "3           3  2020-01-05 02:21:44.378000   \n",
       "4           4  2020-01-19 02:23:02.320000   \n",
       "\n",
       "                                   user_id       os  browser     plan  \\\n",
       "0  196669322373702694527343919754227674361   mac_os  Firefox  monthly   \n",
       "1  196669322373702694527343919754227674361   mac_os  Firefox  monthly   \n",
       "2  212955203693754102065312977639302287127  windows  Firefox  monthly   \n",
       "3  212955203693754102065312977639302287127  windows  Firefox  monthly   \n",
       "4  212955203693754102065312977639302287127  windows  Firefox  monthly   \n",
       "\n",
       "       page  \n",
       "0     merge  \n",
       "1    delete  \n",
       "2       jpg  \n",
       "3    rotate  \n",
       "4  compress  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ds-dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing unrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"Unnamed: 0\", \"ts\", \"os\" , \"browser\", \"plan\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For working with tfrs first we need to convert our dataset to a tf.data.Dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(dict(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset returns a dictionary of page name and user id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': b'merge', 'user_id': b'196669322373702694527343919754227674361'}\n"
     ]
    }
   ],
   "source": [
    "for x in dataset.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model architecture is quite flexible. The inputs can be anything: user ids, os, or timestamps on the query side; page names, plan on the candidate side.\n",
    "\n",
    "In this project, we're going to keep things simple and stick to user ids for the query tower, and pages for the candidate tower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_usage = dataset.map(lambda x: {\n",
    "    \"page\": x[\"page\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "})\n",
    "pages = dataset.map(lambda x: x[\"page\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit and evaluate the model, we need to split it into a training and evaluation set. In an industrial recommender system, this would most likely be done by time: the data up to time *T* would be used to predict interactions after *T*.\n",
    "\n",
    "In this project, however, we'll use a random split, putting 80% of the ratings in the train set, and 20% in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = user_usage.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also figure out unique user ids and pages present in the data.\n",
    "\n",
    "This is important because we need to be able to map the raw values of our categorical features to embedding vectors in our models. To do that, we need a vocabulary that maps a raw feature value to an integer in a contiguous range: this allows us to look up the corresponding embeddings in our embedding tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'compress', b'delete', b'edit', b'excel', b'extract', b'jpg',\n",
       "       b'merge', b'number-pages', b'ppt', b'protect'], dtype=object)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_names = pages.batch(1_000)\n",
    "user_ids = user_usage.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_page_names = np.unique(np.concatenate(list(page_names)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "unique_page_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a model\n",
    "\n",
    "As we are building a two-tower retrieval model, we can build each tower separately and then combine them in the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The query tower\n",
    "The first step is to decide on the dimensionality of the query and candidate representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher values will correspond to models that may be more accurate, but will also be slower to fit and more prone to overfitting.\n",
    "\n",
    "The second is to define the model itself. Here, we're going to use Keras preprocessing layers to first convert user ids to integers, and then convert those to user embeddings via an Embedding layer. Note that we use the list of unique user ids we computed earlier as a vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "      vocabulary=unique_user_ids, mask_token=None),\n",
    "  # We add an additional embedding to account for unknown tokens.\n",
    "  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The candidate tower\n",
    "\n",
    "We can do the same with the candidate tower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "      vocabulary=unique_page_names, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_page_names) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "In our training data we have positive (user, page) pairs. To figure out how good our model is, we need to compare the affinity score that the model calculates for this pair to the scores of all the other possible candidates: if the score for the positive pair is higher than for all other candidates, our model is highly accurate.\n",
    "\n",
    "To do this, we can use the **tfrs.metrics.FactorizedTopK** metric. The metric has one required argument: the dataset of candidates that are used as implicit negatives for evaluation.\n",
    "\n",
    "In our case, that's the page dataset, converted into embeddings via our page model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=pages.batch(128).map(page_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss\n",
    "The next component is the loss used to train our model.\n",
    "\n",
    "In this project, we'll make use of the Retrieval task object: a convenience wrapper that bundles together the loss function and metric computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Retrieval(\n",
    "  metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task itself is a Keras layer that takes the query and candidate embeddings as arguments, and returns the computed loss: we'll use that to implement the model's training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The full model\n",
    "We can now put it all together into a model. TFRS exposes a base model class (tfrs.models.Model) which streamlines building models: all we need to do is to set up the components in the __init__ method, and implement the compute_loss method, taking in the raw features and returning a loss value.\n",
    "\n",
    "The base model will then take care of creating the appropriate training loop to fit our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PageRecModel(tfrs.Model):\n",
    "    def __init__(self, user_model, page_model):\n",
    "        super().__init__()\n",
    "        self.page_model: tf.keras.Model = page_model\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        # And pick out the page feature and pass it into the page model,\n",
    "        # getting embeddings back.\n",
    "        positive_page_embeddings = self.page_model(features[\"page\"])\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(user_embeddings, positive_page_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and evaluating\n",
    "After defining the model, we can use standard Keras fitting and evaluation routines to fit and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PageRecModel(user_model, page_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll shuffle, batch, and cache the training and evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 239s 24s/step - factorized_top_k/top_1_categorical_accuracy: 1.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 1.6250e-04 - factorized_top_k/top_10_categorical_accuracy: 1.6250e-04 - factorized_top_k/top_50_categorical_accuracy: 4.6250e-04 - factorized_top_k/top_100_categorical_accuracy: 4.6250e-04 - loss: 65157.1964 - regularization_loss: 0.0000e+00 - total_loss: 65157.1964\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 236s 24s/step - factorized_top_k/top_1_categorical_accuracy: 0.0176 - factorized_top_k/top_5_categorical_accuracy: 0.0176 - factorized_top_k/top_10_categorical_accuracy: 0.0176 - factorized_top_k/top_50_categorical_accuracy: 0.0187 - factorized_top_k/top_100_categorical_accuracy: 0.0192 - loss: 60079.2923 - regularization_loss: 0.0000e+00 - total_loss: 60079.2923\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 239s 24s/step - factorized_top_k/top_1_categorical_accuracy: 0.0487 - factorized_top_k/top_5_categorical_accuracy: 0.0488 - factorized_top_k/top_10_categorical_accuracy: 0.0490 - factorized_top_k/top_50_categorical_accuracy: 0.0516 - factorized_top_k/top_100_categorical_accuracy: 0.0547 - loss: 59248.8182 - regularization_loss: 0.0000e+00 - total_loss: 59248.8182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e294396748>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the model trains, the loss is falling and a set of top-k retrieval metrics is updated. These tell us whether the true positive is in the top-k retrieved items from the entire candidate set. For example, a top-5 categorical accuracy metric of 0.2 would tell us that, on average, the true positive is in the top 5 retrieved items 20% of the time.\n",
    "\n",
    "Finally, we can evaluate our model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 62s 12s/step - factorized_top_k/top_1_categorical_accuracy: 0.3276 - factorized_top_k/top_5_categorical_accuracy: 0.3787 - factorized_top_k/top_10_categorical_accuracy: 0.3787 - factorized_top_k/top_50_categorical_accuracy: 0.3787 - factorized_top_k/top_100_categorical_accuracy: 0.3787 - loss: 27483.8652 - regularization_loss: 0.0000e+00 - total_loss: 27483.8652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.32760000228881836,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.3787499964237213,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.3787499964237213,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.3787499964237213,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.3787499964237213,\n",
       " 'loss': 24980.08984375,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 24980.08984375}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions\n",
    "\n",
    "Now that we have a model, we would like to be able to make predictions. We can use the tfrs.layers.factorized_top_k.BruteForce layer to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 42: [b'excel' b'excel' b'excel']\n"
     ]
    }
   ],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "# recommends pages out of the entire pages dataset.\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((pages.batch(100), pages.batch(100).map(model.page_model)))\n",
    ")\n",
    "\n",
    "# Get recommendations.\n",
    "_, page_name = index(tf.constant([\"42\"]))\n",
    "print(f\"Recommendations for user 42: {page_name[0, :3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model serving\n",
    "\n",
    "After the model is trained, we need a way to deploy it.\n",
    "\n",
    "In a two-tower retrieval model, serving has two components:\n",
    "\n",
    " \n",
    "\n",
    "*   a serving query model, taking in features of the query and transforming them into a query embedding\n",
    "*   a serving candidate model. This most often takes the form of an approximate nearest neighbours (ANN) index which allows fast approximate lookup of candidates in response to a query produced by the query model\n",
    "\n",
    "In TFRS, both components can be packaged into a single exportable model, giving us a model that takes the raw user id and returns the names of top pages for that user. This is done via exporting the model to a SavedModel format, which makes it possible to serve using TensorFlow Serving.\n",
    "\n",
    "To deploy a model like this, we simply export the BruteForce layer we created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\saeed\\AppData\\Local\\Temp\\tmpvc1e8b6m\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\saeed\\AppData\\Local\\Temp\\tmpvc1e8b6m\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: [b'excel' b'excel' b'excel']\n"
     ]
    }
   ],
   "source": [
    "# Export the query model.\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    path = os.path.join(tmp, \"model\")\n",
    "    \n",
    "    # Save the index.\n",
    "    tf.saved_model.save(index, path)\n",
    "    \n",
    "    # Load it back; can also be done in TensorFlow Serving.\n",
    "    loaded = tf.saved_model.load(path)\n",
    "    \n",
    "    # Pass a user id in, get top predicted page names back.\n",
    "    scores, names = loaded([\"42\"])\n",
    "    \n",
    "    print(f\"Recommendations: {page_name[0][:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End!\n",
    "@saeid Vaghefi, September 26th 2021"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python378",
   "language": "python",
   "name": "python378"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
